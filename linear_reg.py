# -*- coding: utf-8 -*-
"""linear_reg.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TPUiqlc2Dmpgj0k2t6krNNbFRiLkT7gE
"""

class LinearRegression:
    def __init__(self, learning_rate=0.01, epochs=1000):
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = None
        self.bias = 0

    def mse(self,y,y_hat):
      error=0
      for i in range(len(y)):
        error+=(y_hat[i]-y[i])**2
      return error/len(y)

    def compute_y_hat(self, x):
      return sum(x[i] * self.weights[i] for i in range(len(x))) + self.bias


    def compute_gradients(self,X,y):
      n_samples=len(X)
      n_features=len(X[0])
      dw = [0]*n_features
      db = 0
      for j in range(n_samples):
        y_pred=self.compute_y_hat(X[j])
        error=y[j]-y_pred
        for i in range(n_features):
            dw[i] += error * X[j][i]


        db+=error
        dw = [-(2 / n_samples) * dwi for dwi in dw]
        db *= -(2 / n_samples)

      return dw, db

    def descent(self,dw,db):
      for i in range(len(self.weights)):
        self.weights[i] -= self.learning_rate * dw[i]
      self.bias -= self.learning_rate * db

    def fit(self, X, y):
        n_features = len(X[0])
        self.weights = [0] * n_features
        initial_w, initial_b = self.weights[:], self.bias

        for _ in range(self.epochs):
            dw, db = self.compute_gradients(X, y)
            self.descent(dw, db)

        return initial_w, initial_b

    def predict(self, X):
        return [self.compute_y_hat(x) for x in X]

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = [[1], [2], [3], [4], [5]]
y = [-1, -2, -3, -4, -5]
model = LinearRegression(learning_rate=0.01, epochs=1000)
initial_w, initial_b = model.fit(X, y)
y_pred_initial = [x[0] * initial_w[0] + initial_b for x in X]
y_pred_final = model.predict(X)


plt.figure(figsize=(8, 6))
plt.scatter([x[0] for x in X], y, color='blue', label='Actual Data')
plt.plot([x[0] for x in X], y_pred_initial, color='gray', linestyle='dashed', label='Initial Line')
plt.plot([x[0] for x in X], y_pred_final, color='red', label='Final Fit')
plt.xlabel("Feature Value")
plt.ylabel("Target Value")
plt.title("Linear Regression Training Process")
plt.legend()
plt.show()



